{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my finetuned dataset, what I'm doing is download the top ten most popular jp novels from the site novelupdates.com. Then using the japanese title found on this page and downloading the japanse webnovel from syosetsu. While I could try and automate this part, I don't really have the front end experience to do so. That is also not the focus of this project.\n",
    "\n",
    "So I realized that encoding the JP and the EN parts separately would mean they wouldn't be able to talk to each other. I created the file below to turn into my now reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translation</th>\n",
       "      <th>EN_for_now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま瞬く間に他の国を...</td>\n",
       "      <td>And having surpassed his older brother Budari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に白米を食していた。</td>\n",
       "      <td>His uncle on Earth hadn’t gone as far as to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該当する文化圏にあ...</td>\n",
       "      <td>However, in the military nation in Origin tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作るべきかと思った...</td>\n",
       "      <td>Vandalieu had been wondering whether he shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発動。ただでさえ残...</td>\n",
       "      <td>She brandished her whip and activated ‘Transc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの』</td>\n",
       "      <td>『A skill is the transformation of part of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことです。この世界の住...</td>\n",
       "      <td>「Referring to what you said a short while ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！</td>\n",
       "      <td>I repeat, the clones are to support the main ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>《確認しました。対熱耐性獲得・・・成功しました》</td>\n",
       "      <td>&lt;&lt;Confirmed. Establishing heat resistance. Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？</td>\n",
       "      <td>Just an hour please, let me catch my breath. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>１，２，３，ダァー！！！</td>\n",
       "      <td>1, 2, 3, Daaaaa!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>《カルマン、思念波を感知したわ。間違いなくこの波長は、貴方の記憶情報にあるミッシェル様のもの...</td>\n",
       "      <td>&lt;&lt;Karman, I detected the thought waves. They ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>「信じられぬだろうが、私は操られていたのだ。ミッシェル様を救出に向かいたいので、この場は私を...</td>\n",
       "      <td>“You may not believe it, but I was being cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>仮に、俺の存在に気付きヴェルダが迷宮を封印しようとしたとしても、今の俺なら本体との『多重並列...</td>\n",
       "      <td>For argument’s sake, even if Velda had tried ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>竜種すらも滅ぼそうかという超々高密度の破壊のエネルギーの渦に、覚醒魔王級とはいえ、一介の堕天...</td>\n",
       "      <td>Because she couldn’t believe that a fallen an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>左胴を狙った斬撃をハロルドは右手１本で握った竹刀で遮ろうとする。</td>\n",
       "      <td>Harold tried to intercept the slash aimed at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>いきなり子ども以下の惨めな雑魚、などと罵られたアイリーンからするとロビンソンの意見は受け入れ...</td>\n",
       "      <td>All of a sudden being insulted as a miserable...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Translation  \\\n",
       "0   そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま瞬く間に他の国を...   \n",
       "1    地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に白米を食していた。    \n",
       "2   しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該当する文化圏にあ...   \n",
       "3   荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作るべきかと思った...   \n",
       "4   しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発動。ただでさえ残...   \n",
       "5            『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの』    \n",
       "6   「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことです。この世界の住...   \n",
       "7               繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！    \n",
       "8                           《確認しました。対熱耐性獲得・・・成功しました》    \n",
       "9                  時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？    \n",
       "10                                      １，２，３，ダァー！！！    \n",
       "11  《カルマン、思念波を感知したわ。間違いなくこの波長は、貴方の記憶情報にあるミッシェル様のもの...   \n",
       "12  「信じられぬだろうが、私は操られていたのだ。ミッシェル様を救出に向かいたいので、この場は私を...   \n",
       "13  仮に、俺の存在に気付きヴェルダが迷宮を封印しようとしたとしても、今の俺なら本体との『多重並列...   \n",
       "14  竜種すらも滅ぼそうかという超々高密度の破壊のエネルギーの渦に、覚醒魔王級とはいえ、一介の堕天...   \n",
       "15                  左胴を狙った斬撃をハロルドは右手１本で握った竹刀で遮ろうとする。    \n",
       "16  いきなり子ども以下の惨めな雑魚、などと罵られたアイリーンからするとロビンソンの意見は受け入れ...   \n",
       "\n",
       "                                           EN_for_now  \n",
       "0    And having surpassed his older brother Budari...  \n",
       "1    His uncle on Earth hadn’t gone as far as to s...  \n",
       "2    However, in the military nation in Origin tha...  \n",
       "3    Vandalieu had been wondering whether he shoul...  \n",
       "4    She brandished her whip and activated ‘Transc...  \n",
       "5    『A skill is the transformation of part of the...  \n",
       "6    「Referring to what you said a short while ago...  \n",
       "7    I repeat, the clones are to support the main ...  \n",
       "8    <<Confirmed. Establishing heat resistance. Su...  \n",
       "9    Just an hour please, let me catch my breath. ...  \n",
       "10                                 1, 2, 3, Daaaaa!!!  \n",
       "11   <<Karman, I detected the thought waves. They ...  \n",
       "12   “You may not believe it, but I was being cont...  \n",
       "13   For argument’s sake, even if Velda had tried ...  \n",
       "14   Because she couldn’t believe that a fallen an...  \n",
       "15   Harold tried to intercept the slash aimed at ...  \n",
       "16   All of a sudden being insulted as a miserable...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"C:/Users/Dylan/Downloads/syosetu/Sentence Pairs.txt\", sep=\"|\", header=None, encoding=\"utf-8\")\n",
    "dataframe.columns = [\"Translation\", \"EN_for_now\"]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ended up having to do some manipulation dataframe manipulation to get the tokenizer to recognize the dataset I created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"Translation\"] = \"\\\"jp\\\": \" + dataframe[\"Translation\"]\n",
    "dataframe[\"EN_for_now\"] = \"\\\"en\\\": \" + dataframe[\"EN_for_now\"]\n",
    "dataframe[\"Translation\"] = dataframe[\"Translation\"] + \", \" + dataframe[\"EN_for_now\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop([\"EN_for_now\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"jp\": そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま瞬く...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"jp\": 地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に白米...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"jp\": しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該当す...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"jp\": 荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作るべ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"jp\": しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発動。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"jp\": 『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの』 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"jp\": 「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことです。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"jp\": 繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！ , \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"jp\": 《確認しました。対熱耐性獲得・・・成功しました》 , \"en\":  &lt;&lt;Conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"jp\": 時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？ , \"en\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"jp\": １，２，３，ダァー！！！ , \"en\":  1, 2, 3, Daaaaa!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"jp\": 《カルマン、思念波を感知したわ。間違いなくこの波長は、貴方の記憶情報にあるミッシ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"jp\": 「信じられぬだろうが、私は操られていたのだ。ミッシェル様を救出に向かいたいので、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"jp\": 仮に、俺の存在に気付きヴェルダが迷宮を封印しようとしたとしても、今の俺なら本体と...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"jp\": 竜種すらも滅ぼそうかという超々高密度の破壊のエネルギーの渦に、覚醒魔王級とはいえ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"jp\": 左胴を狙った斬撃をハロルドは右手１本で握った竹刀で遮ろうとする。 , \"en\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"jp\": いきなり子ども以下の惨めな雑魚、などと罵られたアイリーンからするとロビンソンの意...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Translation\n",
       "0   \"jp\": そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま瞬く...\n",
       "1   \"jp\": 地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に白米...\n",
       "2   \"jp\": しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該当す...\n",
       "3   \"jp\": 荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作るべ...\n",
       "4   \"jp\": しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発動。...\n",
       "5   \"jp\": 『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの』 ...\n",
       "6   \"jp\": 「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことです。...\n",
       "7   \"jp\": 繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！ , \"...\n",
       "8   \"jp\": 《確認しました。対熱耐性獲得・・・成功しました》 , \"en\":  <<Conf...\n",
       "9   \"jp\": 時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？ , \"en\"...\n",
       "10     \"jp\": １，２，３，ダァー！！！ , \"en\":  1, 2, 3, Daaaaa!!!\n",
       "11  \"jp\": 《カルマン、思念波を感知したわ。間違いなくこの波長は、貴方の記憶情報にあるミッシ...\n",
       "12  \"jp\": 「信じられぬだろうが、私は操られていたのだ。ミッシェル様を救出に向かいたいので、...\n",
       "13  \"jp\": 仮に、俺の存在に気付きヴェルダが迷宮を封印しようとしたとしても、今の俺なら本体と...\n",
       "14  \"jp\": 竜種すらも滅ぼそうかという超々高密度の破壊のエネルギーの渦に、覚醒魔王級とはいえ...\n",
       "15  \"jp\": 左胴を狙った斬撃をハロルドは右手１本で握った竹刀で遮ろうとする。 , \"en\":...\n",
       "16  \"jp\": いきなり子ども以下の惨めな雑魚、などと罵られたアイリーンからするとロビンソンの意..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Translation'],\n",
       "    num_rows: 17\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(dataframe.applymap(str))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"jp\": そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま瞬く間に他の国を支配し、自分を頂点とした弱肉強食の世界支配が始まるはずだった。 , \"en\":  And having surpassed his older brother Budarion, Bugitas finally stole the throne. And from there, he was supposed to have conquered the other nations in the blink of an eye and begin ruling a world of survival of the fittest, where he sat at the top.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"Translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed59004d979499999d936de0eb6817e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Translation', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 17\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Translation\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenized_train, tokenized_test = train_test_split(tokenized_datasets, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf6e621422e442695f5e8cdc81c6848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ea56f718d45d49d980cdaa9af4f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\DK30\\Machine-Learning-Translator\\DK30 Data Set.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/DK30/Machine-Learning-Translator/DK30%20Data%20Set.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1556\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1560\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\trainer.py:1815\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1812\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1814\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 1815\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1816\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1817\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\accelerate\\data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[0;32m    452\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
