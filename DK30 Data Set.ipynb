{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my finetuned dataset, what I'm doing is download the top ten most popular jp novels from the site novelupdates.com. Then using the japanese title found on this page and downloading the japanse webnovel from syosetsu. While I could try and automate this part, I don't really have the front end experience to do so. That is also not the focus of this project.\n",
    "\n",
    "So I realized that encoding the JP and the EN parts separately would mean they wouldn't be able to talk to each other. I created the file below to turn into my now reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>EN_for_now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま瞬く間に他の国を...</td>\n",
       "      <td>And having surpassed his older brother Budari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に白米を食していた。</td>\n",
       "      <td>His uncle on Earth hadn’t gone as far as to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該当する文化圏にあ...</td>\n",
       "      <td>However, in the military nation in Origin tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作るべきかと思った...</td>\n",
       "      <td>Vandalieu had been wondering whether he shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発動。ただでさえ残...</td>\n",
       "      <td>She brandished her whip and activated ‘Transc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの』</td>\n",
       "      <td>『A skill is the transformation of part of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことです。この世界の住...</td>\n",
       "      <td>「Referring to what you said a short while ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！</td>\n",
       "      <td>I repeat, the clones are to support the main ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>《確認しました。対熱耐性獲得・・・成功しました》</td>\n",
       "      <td>&lt;&lt;Confirmed. Establishing heat resistance. Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？</td>\n",
       "      <td>Just an hour please, let me catch my breath. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>１，２，３，ダァー！！！</td>\n",
       "      <td>1, 2, 3, Daaaaa!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>《カルマン、思念波を感知したわ。間違いなくこの波長は、貴方の記憶情報にあるミッシェル様のもの...</td>\n",
       "      <td>&lt;&lt;Karman, I detected the thought waves. They ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>「信じられぬだろうが、私は操られていたのだ。ミッシェル様を救出に向かいたいので、この場は私を...</td>\n",
       "      <td>“You may not believe it, but I was being cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>仮に、俺の存在に気付きヴェルダが迷宮を封印しようとしたとしても、今の俺なら本体との『多重並列...</td>\n",
       "      <td>For argument’s sake, even if Velda had tried ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>竜種すらも滅ぼそうかという超々高密度の破壊のエネルギーの渦に、覚醒魔王級とはいえ、一介の堕天...</td>\n",
       "      <td>Because she couldn’t believe that a fallen an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>左胴を狙った斬撃をハロルドは右手１本で握った竹刀で遮ろうとする。</td>\n",
       "      <td>Harold tried to intercept the slash aimed at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>いきなり子ども以下の惨めな雑魚、などと罵られたアイリーンからするとロビンソンの意見は受け入れ...</td>\n",
       "      <td>All of a sudden being insulted as a miserable...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          translation  \\\n",
       "0   そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま瞬く間に他の国を...   \n",
       "1    地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に白米を食していた。    \n",
       "2   しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該当する文化圏にあ...   \n",
       "3   荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作るべきかと思った...   \n",
       "4   しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発動。ただでさえ残...   \n",
       "5            『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの』    \n",
       "6   「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことです。この世界の住...   \n",
       "7               繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！    \n",
       "8                           《確認しました。対熱耐性獲得・・・成功しました》    \n",
       "9                  時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？    \n",
       "10                                      １，２，３，ダァー！！！    \n",
       "11  《カルマン、思念波を感知したわ。間違いなくこの波長は、貴方の記憶情報にあるミッシェル様のもの...   \n",
       "12  「信じられぬだろうが、私は操られていたのだ。ミッシェル様を救出に向かいたいので、この場は私を...   \n",
       "13  仮に、俺の存在に気付きヴェルダが迷宮を封印しようとしたとしても、今の俺なら本体との『多重並列...   \n",
       "14  竜種すらも滅ぼそうかという超々高密度の破壊のエネルギーの渦に、覚醒魔王級とはいえ、一介の堕天...   \n",
       "15                  左胴を狙った斬撃をハロルドは右手１本で握った竹刀で遮ろうとする。    \n",
       "16  いきなり子ども以下の惨めな雑魚、などと罵られたアイリーンからするとロビンソンの意見は受け入れ...   \n",
       "\n",
       "                                           EN_for_now  \n",
       "0    And having surpassed his older brother Budari...  \n",
       "1    His uncle on Earth hadn’t gone as far as to s...  \n",
       "2    However, in the military nation in Origin tha...  \n",
       "3    Vandalieu had been wondering whether he shoul...  \n",
       "4    She brandished her whip and activated ‘Transc...  \n",
       "5    『A skill is the transformation of part of the...  \n",
       "6    「Referring to what you said a short while ago...  \n",
       "7    I repeat, the clones are to support the main ...  \n",
       "8    <<Confirmed. Establishing heat resistance. Su...  \n",
       "9    Just an hour please, let me catch my breath. ...  \n",
       "10                                 1, 2, 3, Daaaaa!!!  \n",
       "11   <<Karman, I detected the thought waves. They ...  \n",
       "12   “You may not believe it, but I was being cont...  \n",
       "13   For argument’s sake, even if Velda had tried ...  \n",
       "14   Because she couldn’t believe that a fallen an...  \n",
       "15   Harold tried to intercept the slash aimed at ...  \n",
       "16   All of a sudden being insulted as a miserable...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"C:/Users/Dylan/Downloads/syosetu/Sentence Pairs.txt\", sep=\"|\", header=None, encoding=\"utf-8\")\n",
    "dataframe.columns = [\"translation\", \"EN_for_now\"]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ended up having to do some manipulation dataframe manipulation to get the tokenizer to recognize the dataset I created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"translation\"] = \"\\\"jp\\\": \" + '\"' + dataframe[\"translation\"] + '\"'\n",
    "dataframe[\"EN_for_now\"] = \"\\\"en\\\": \" + '\"'  + dataframe[\"EN_for_now\"] + '\"'\n",
    "dataframe[\"translation\"] = '{' + dataframe[\"translation\"] + \", \" + dataframe[\"EN_for_now\"] + '}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop([\"EN_for_now\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"jp\": \"そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"jp\": \"地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"jp\": \"しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"jp\": \"荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"jp\": \"しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{\"jp\": \"『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{\"jp\": \"「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことで...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{\"jp\": \"繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！ \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{\"jp\": \"《確認しました。対熱耐性獲得・・・成功しました》 \", \"en\": \" &lt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{\"jp\": \"時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？ \", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{\"jp\": \"１，２，３，ダァー！！！ \", \"en\": \" 1, 2, 3, Daaaa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          translation\n",
       "0   {\"jp\": \"そして兄ブダリオンを超えたブギータスは、遂に帝位を奪い取った。そしてそのまま...\n",
       "1   {\"jp\": \"地球での伯父も流石に白米を食べる事を贅沢だとは言わなかったので、当時は普通に...\n",
       "2   {\"jp\": \"しかし、オリジンで二度目の人生を過ごした軍事国家の研究所は、地球の欧州圏に該...\n",
       "3   {\"jp\": \"荷物の運搬の為に、嫌悪感を抑えて空間属性魔術を使うグーバモンのアンデッドを作...\n",
       "4   {\"jp\": \"しかしテイマーの女は諦めない。鞭を振るい、【限界超越】、【魔鞭限界突破】を発...\n",
       "5   {\"jp\": \"『スキルとは、生物が持つ魂の力を簡単に引き出すために、魂の一部を改変したもの...\n",
       "6   {\"jp\": \"「さきほどあなたがおっしゃったのは、ＭＡエネルギーだけに焦点を合わせたことで...\n",
       "7   {\"jp\": \"繰り返す、分体は本体の思考をサポートし、口が滑らかに動くように尽力せよ！ \"...\n",
       "8   {\"jp\": \"《確認しました。対熱耐性獲得・・・成功しました》 \", \"en\": \" <<...\n",
       "9   {\"jp\": \"時間をくれ、落ち着くから。こういう時は素数を数えたらいいんだっけ？ \", \"...\n",
       "10  {\"jp\": \"１，２，３，ダァー！！！ \", \"en\": \" 1, 2, 3, Daaaa..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ja-en\", return_tensors=\"pt\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ja-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "testDataset = load_dataset(\"open_subtitles\", \"bn-is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "openDs = pd.DataFrame(testDataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'bn': 'হবিটোস কাছে কোথাও আছে.', 'is': 'Eitrið...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'bn': 'বিষ এখনো তাজা, তিন দিন ধরে.', 'is': 'Þ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'bn': 'তারা আমাদের পিছু নিয়েছে.', 'is': 'Ef þ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'bn': 'এটাই সেটা.', 'is': 'Hér komst Forresta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'bn': 'এটাকেই ফরেস্টাল খুঁজেছিল.', 'is': '- E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38267</th>\n",
       "      <td>38267</td>\n",
       "      <td>{'bn': 'অস্ত্র ফেলে দাও!', 'is': 'Slepptu vopn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38268</th>\n",
       "      <td>38268</td>\n",
       "      <td>{'bn': 'ফেলো! এক্ষণ!', 'is': 'Slepptu því núna!'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38269</th>\n",
       "      <td>38269</td>\n",
       "      <td>{'bn': 'মাটিতে শুয়ে পড়ো!', 'is': 'Á jörðina nú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38270</th>\n",
       "      <td>38270</td>\n",
       "      <td>{'bn': 'সিজ অল মোটর ফাংশনস!', 'is': 'Frystið a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38271</th>\n",
       "      <td>38271</td>\n",
       "      <td>{'bn': 'সিজ অল মোটর ফাংশনস!', 'is': 'Frystið a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                        translation\n",
       "0          0  {'bn': 'হবিটোস কাছে কোথাও আছে.', 'is': 'Eitrið...\n",
       "1          1  {'bn': 'বিষ এখনো তাজা, তিন দিন ধরে.', 'is': 'Þ...\n",
       "2          2  {'bn': 'তারা আমাদের পিছু নিয়েছে.', 'is': 'Ef þ...\n",
       "3          3  {'bn': 'এটাই সেটা.', 'is': 'Hér komst Forresta...\n",
       "4          4  {'bn': 'এটাকেই ফরেস্টাল খুঁজেছিল.', 'is': '- E...\n",
       "...      ...                                                ...\n",
       "38267  38267  {'bn': 'অস্ত্র ফেলে দাও!', 'is': 'Slepptu vopn...\n",
       "38268  38268  {'bn': 'ফেলো! এক্ষণ!', 'is': 'Slepptu því núna!'}\n",
       "38269  38269  {'bn': 'মাটিতে শুয়ে পড়ো!', 'is': 'Á jörðina nú...\n",
       "38270  38270  {'bn': 'সিজ অল মোটর ফাংশনস!', 'is': 'Frystið a...\n",
       "38271  38271  {'bn': 'সিজ অল মোটর ফাংশনস!', 'is': 'Frystið a...\n",
       "\n",
       "[38272 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "openDs.drop(\"meta\", axis=1, inplace=True)\n",
    "openDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dylan\\AppData\\Local\\Temp\\ipykernel_62240\\2461113079.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  dataset = Dataset.from_pandas(dataframe.applymap(str))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 17\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = Dataset.from_pandas(dataframe.applymap(str))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn': 'আমরা... ...পিপাসার্ত নই.', 'is': '- Hvað er þér á höndum?'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset[\"Translation\"][0]\n",
    "testDataset[\"train\"][\"translation\"][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedTestDatasetTrain = testDataset[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"translation\"], padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2079f8c087644a9b9a1c8585991c7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 17\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets\n",
    "#tokenizedTestDatasetTrain = tokenizedTestDatasetTrain.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 11\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 6\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.3)\n",
    "tokenized_datasets[\"test\"][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't get the trainer to work so I'm trying it in pytorch. All of the code below is copied from the huggingface translation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=8)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"test_jp-en\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(60716, 512, padding_idx=60715)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(60716, 512, padding_idx=60715)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(60716, 512, padding_idx=60715)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=60716, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    return decoded_preds, decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"jp_en_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2905837dfeaf437c8d3f73c9e397f411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`translation` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:748\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 748\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[0;32m    750\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[0;32m    751\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[0;32m    755\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:720\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[1;34m(value, dtype)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(value))\n\u001b[1;32m--> 720\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mtensor(value)\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan\\Documents\\(Notepad)\\DK30\\Machine-Learning-Translator\\DK30 Data Set.ipynb Cell 36\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/DK30/Machine-Learning-Translator/DK30%20Data%20Set.ipynb#X52sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_train_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/DK30/Machine-Learning-Translator/DK30%20Data%20Set.ipynb#X52sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Training\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/DK30/Machine-Learning-Translator/DK30%20Data%20Set.ipynb#X52sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/DK30/Machine-Learning-Translator/DK30%20Data%20Set.ipynb#X52sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m train_dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/DK30/Machine-Learning-Translator/DK30%20Data%20Set.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         outputs \u001b[39m=\u001b[39;49m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dylan/Documents/%28Notepad%29/DK30/Machine-Learning-Translator/DK30%20Data%20Set.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         loss \u001b[39m=\u001b[39;49m outputs\u001b[39m.\u001b[39;49mloss\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\accelerate\\data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[0;32m    452\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\data\\data_collator.py:586\u001b[0m, in \u001b[0;36mDataCollatorForSeq2Seq.__call__\u001b[1;34m(self, features, return_tensors)\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m             feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([remainder, feature[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]])\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n\u001b[1;32m--> 586\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad(\n\u001b[0;32m    587\u001b[0m     features,\n\u001b[0;32m    588\u001b[0m     padding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[0;32m    589\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_length,\n\u001b[0;32m    590\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m    591\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m    592\u001b[0m )\n\u001b[0;32m    594\u001b[0m \u001b[39m# prepare decoder_input_ids\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    596\u001b[0m     labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    598\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mprepare_decoder_input_ids_from_labels\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    599\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3295\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   3292\u001b[0m             batch_outputs[key] \u001b[39m=\u001b[39m []\n\u001b[0;32m   3293\u001b[0m         batch_outputs[key]\u001b[39m.\u001b[39mappend(value)\n\u001b[1;32m-> 3295\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(batch_outputs, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:223\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    219\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[1;32m--> 223\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[1;32mc:\\Users\\Dylan\\mambaforge-pypy3\\envs\\fastai\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:764\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    760\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    761\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    762\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    763\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    765\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    767\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m features (`\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    768\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    769\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`translation` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "            )\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(generated_tokens)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        #repo.push_to_hub(\n",
    "         #   commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        #)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
